version: 2.1

defaults: &defaults
  docker:
    - image: circleci/buildpack-deps:xenial-scm
  working_directory: ~/ENCODE-DCC/wgbs-pipeline

machine_defaults: &machine_defaults
  machine:
    image: circleci/classic:latest
  working_directory: ~/ENCODE-DCC/wgbs-pipeline

py37: &py37
  docker:
    - image: circleci/python:3.7.4-stretch
  working_directory: ~/ENCODE-DCC/wgbs-pipeline

lint: &lint
  docker:
    - image: quay.io/encode-dcc/wgbs-pipeline:circleci-lint
  working_directory: ~/ENCODE-DCC/wgbs-pipeline

rust: &rust
  docker:
    - image: circleci/rust:1.40.0-stretch
  working_directory: ~/ENCODE-DCC/wgbs-pipeline

make_tag: &make_tag
  name: make docker image tag
  command: |
    echo "export TAG=quay.io/encode-dcc/${CIRCLE_PROJECT_REPONAME}:${CIRCLE_BRANCH}_${CIRCLE_WORKFLOW_ID}" >> ${BASH_ENV}

set_quay_repo: &set_quay_repo
  name: set quay repo env var
  command: |
    echo "export QUAY_REPO=wgbs-pipeline" >> ${BASH_ENV}

get_caper: &get_caper
  name: get caper
  command: |
    pyenv global 3.5.2
    pip3 install caper==0.7.0

get_md5_script: &get_md5_script
  name: get compare_md5.py script
  command: |
    curl -O https://raw.githubusercontent.com/ENCODE-DCC/rna-seq-pipeline/master/src/compare_md5.py

commands:
  run_tox:
    description: "Install and run tox with a given environment"
    parameters:
      toxenv:
        description: "The name of the environment as per tox.ini, e.g. py37 or lint"
        type: string
      extra_args:
        description: "Extra arguments that are consumed only when running pytest"
        type: string
        default: ""
    steps:
      - run: sudo pip install tox
      - run: tox -e << parameters.toxenv >> -- << parameters.extra_args >>

jobs:
  lint:
    <<: *lint
    steps:
      - checkout
      - run: cat "${HOME}/.cargo/env" >> ${BASH_ENV}
      - run_tox:
          toxenv: "lint"
  test_py37:
    <<: *py37
    steps:
      - checkout
      - run_tox:
          toxenv: "py37"
  coverage-report:
    <<: *py37
    steps:
      - checkout
      - run_tox:
          toxenv: "coverage-report"
  test_rust:
    <<: *rust
    steps:
      - checkout
      - run: cargo test
  test_wdl:
    <<: *machine_defaults
    description: Generic testing protocol for wdl tasks
    parameters:
      test_name:
        description: "The name of the test being performed, like align, merge, etc."
        type: string
      is_workflow:
        default: false
        description: "Describes if the test is for a task or for a workflow"
        type: boolean
      keys_to_inspect:
        description: "The key(s) of the output(s) in metadata.json for which md5sum is to be computed, space delimited"
        type: string
      resource_class:
        description: "The machine resource class to run the test with"
        type: string
        default: medium
    resource_class: << parameters.resource_class >>
    steps:
      - when:
          condition: << parameters.is_workflow >>
          steps:
            - checkout
            - run: *make_tag
            - run: *get_caper
            - run: *get_md5_script
            - run:
                command: |
                  source ${BASH_ENV}
                  tests/wdl/test.sh wgbs-pipeline.wdl tests/wdl/test_workflow/test_<< parameters.test_name >>_input.json "${TAG}"
                  python3 compare_md5.py --keys_to_inspect << parameters.keys_to_inspect >> --metadata_json wgbs-pipeline.metadata.json --reference_json tests/wdl/test_workflow/ref_output/test_<< parameters.test_name >>_output_md5.json --outfile result.json
                  cat result.json
                  python3 -c "import sys; import json; data=json.loads(sys.stdin.read()); sys.exit(int(not data['match_overall']))" < result.json
                no_output_timeout: 30m
      - unless:
          condition: << parameters.is_workflow >>
          steps:
            - checkout
            - run: *make_tag
            - run: *get_caper
            - run: *get_md5_script
            - run:
                command: |
                  source ${BASH_ENV}
                  tests/wdl/test.sh tests/wdl/test_task/test_<< parameters.test_name >>.wdl tests/wdl/test_task/test_<< parameters.test_name >>_input.json "${TAG}"
                  python3 compare_md5.py --keys_to_inspect << parameters.keys_to_inspect >> --metadata_json test_<< parameters.test_name >>.metadata.json --reference_json tests/wdl/test_task/ref_output/test_<< parameters.test_name >>_output_md5.json --outfile result.json
                  cat result.json
                  python3 -c "import sys; import json; data=json.loads(sys.stdin.read()); sys.exit(int(not data['match_overall']))" < result.json
                no_output_timeout: 30m

  build:
    <<: *defaults
    steps:
      - checkout
      - setup_remote_docker
      - run: *make_tag
      - run: *set_quay_repo
      - run:
          name: build image
          command: |
            source ${BASH_ENV}
            echo "pulling template!"
            docker pull quay.io/encode-dcc/${QUAY_REPO}:template
            docker login -u=${QUAY_ROBOT_USER} -p=${QUAY_ROBOT_USER_TOKEN} quay.io
            docker build --cache-from quay.io/encode-dcc/${QUAY_REPO}:template --build-arg GIT_COMMIT_HASH=${CIRCLE_SHA1} --build-arg BRANCH=${CIRCLE_BRANCH} --build-arg BUILD_TAG=${TAG} -t "${TAG}" -t quay.io/encode-dcc/${QUAY_REPO}:template -f Dockerfile .
            docker push "${TAG}"
            docker logout
          no_output_timeout: 30m

  push_template:
    <<: *defaults
    steps:
      - checkout
      - setup_remote_docker
      - run: *make_tag
      - run: *set_quay_repo
      - run:
          command: |
            source ${BASH_ENV}
            docker pull "${TAG}"
            docker login -u=${QUAY_ROBOT_USER} -p=${QUAY_ROBOT_USER_TOKEN} quay.io
            docker tag "${TAG}" quay.io/encode-dcc/${QUAY_REPO}:template
            docker push quay.io/encode-dcc/${QUAY_REPO}:template
            docker logout
          no_output_timeout: 30m

# Define workflow here
workflows:
  version: 2
  build_workflow:
    jobs:
      - build
      - lint
      - coverage-report
      - test_py37:
          requires:
            - build
            - lint
      - test_rust:
          requires:
            - build
            - lint
      - test_wdl:
          name: test_make_metadata_csv_and_conf
          requires:
            - build
            - lint
          test_name: "make_metadata_csv_and_conf"
          keys_to_inspect: "test_make_metadata_csv_and_conf.make_metadata_csv_and_conf.metadata_csv test_make_metadata_csv_and_conf.make_metadata_csv_and_conf.gembs_conf"
      - test_wdl:
          name: test_index
          requires:
            - build
            - lint
          test_name: "index"
          keys_to_inspect: "test_index.index.contig_sizes test_index.index.gembs_indexes test_index.index.gemBS_json"
      - test_wdl:
          name: test_prepare
          requires:
            - build
            - lint
          test_name: "prepare"
          keys_to_inspect: "test_prepare.prepare.gemBS_json"
      - test_wdl:
          name: test_map
          requires:
            - build
            - lint
          test_name: "map"
          resource_class: large
          keys_to_inspect: "test_map.map.bam test_map.map.csi test_map.map.bam_md5 test_map.map.qc_json"
      - test_wdl:
          name: test_bscaller
          requires:
            - build
            - lint
          test_name: "bscaller"
          # bscaller qc json not deterministic due to random ordering, so don't check
          keys_to_inspect: "test_bscaller.bscaller.bcf test_bscaller.bscaller.bcf_csi test_bscaller.bscaller.bcf_md5"
      - test_wdl:
          name: test_extract
          requires:
            - build
            - lint
          test_name: "extract"
          keys_to_inspect: "test_extract.extract.cpg_txt test_extract.extract.chh_bed test_extract.extract.chg_bb test_extract.extract.cpg_bed test_extract.extract.non_cpg_txt_tbi test_extract.extract.chg_bed test_extract.extract.non_cpg_txt test_extract.extract.chh_bb test_extract.extract.bw test_extract.extract.cpg_txt_tbi test_extract.extract.cpg_bb"
      - test_wdl:
          name: test_bsmooth
          requires:
            - build
            - lint
          test_name: "bsmooth"
          keys_to_inspect: "test_bsmooth.bsmooth.smoothed_cpg_bed test_bsmooth.bsmooth.smoothed_cpg_bigbed"
      - test_wdl:
          name: test_qc_report
          requires:
            - build
            - lint
          test_name: "qc_report"
          keys_to_inspect: "test_qc_report.qc_report.map_html_assets test_qc_report.qc_report.portal_map_qc_json"
      - test_wdl:
          name: test_wgbs
          requires:
            - build
            - lint
          test_name: wgbs
          is_workflow: true
          resource_class: large
          # wgbs.bscaller.qc_json is not consistent (contigs in random order)
          keys_to_inspect: "wgbs.make_metadata_csv_and_conf.gembs_conf wgbs.make_metadata_csv_and_conf.metadata_csv wgbs.index_reference.gembs_indexes wgbs.index_reference.gemBS_json wgbs.index_reference.contig_sizes wgbs.map.csi wgbs.map.bam wgbs.map.bam_md5 wgbs.map.qc_json wgbs.bscaller.bcf_csi wgbs.bscaller.bcf wgbs.bscaller.bcf_md5 wgbs.extract.cpg_txt wgbs.extract.chh_bed wgbs.extract.chg_bb wgbs.extract.cpg_bed wgbs.extract.non_cpg_txt_tbi wgbs.extract.chg_bed wgbs.extract.non_cpg_txt wgbs.extract.chh_bb wgbs.extract.bw wgbs.extract.cpg_txt_tbi wgbs.extract.cpg_bb wgbs.qc_report.map_html_assets wgbs.qc_report.portal_map_qc_json"
      - push_template:
          requires:
            - build
            - lint
            - coverage-report
            - test_py37
            - test_rust
            - test_make_metadata_csv_and_conf
            - test_bsmooth
          filters:
            branches:
              only:
                - dev
                - master
